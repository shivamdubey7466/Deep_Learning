{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Click on [Data](http://www.ats.ucla.edu/stat/data/binary.csv) to fetch the data for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>GPE</th>\n",
       "      <th>GRE</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  GPE   GRE  Rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('binary.csv',sep=',',names=['label','GPE','GRE','Rank'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.061681546652096e-16\t\t1.0012523486435176\n"
     ]
    }
   ],
   "source": [
    "features=df.drop(columns='label')\n",
    "labels=df['label']\n",
    "\n",
    "\n",
    "features_with_dummies=pd.get_dummies(data=features,columns=['Rank'])\n",
    "scaler=StandardScaler()\n",
    "\n",
    "cols=['GPE','GRE']\n",
    "\n",
    "features_with_dummies[cols]=scaler.fit_transform(features_with_dummies[cols])\n",
    "features_with_dummies.head()\n",
    "\n",
    "print(str(features_with_dummies['GPE'].mean())+'\\t\\t'+ str(features_with_dummies['GPE'].std()))\n",
    "\n",
    "#np.random.seed(43)\n",
    "\n",
    "test_indices=np.random.choice(features_with_dummies.index,size=int(len(features_with_dummies)*0.1), replace=False)\n",
    "\n",
    "test_features,test_labels=features_with_dummies.iloc[test_indices], labels.iloc[test_indices]\n",
    "\n",
    "train_indices=np.setdiff1d(np.array(features_with_dummies.index),np.array(test_indices))\n",
    "\n",
    "train_features,train_labels=features_with_dummies.iloc[train_indices],labels.iloc[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "n_rows,n_features=train_features.shape\n",
    "print(n_features)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.22571551776986504\n",
      "Train loss:  0.19704585985276044\n",
      "Train loss:  0.1970433162015207\n",
      "Train loss:  0.19704331519357451\n",
      "Train loss:  0.19704331519317483\n",
      "Train loss:  0.1970433151931745\n",
      "Train loss:  0.19704331519317447\n",
      "Train loss:  0.19704331519317447\n",
      "Train loss:  0.19704331519317447\n",
      "Train loss:  0.19704331519317447\n",
      "Prediction accuracy: 0.800\n"
     ]
    }
   ],
   "source": [
    "learnrate=0.5\n",
    "weights=np.random.normal(scale=1/np.sqrt(n_features), size=n_features)\n",
    "bias=0\n",
    "\n",
    "\n",
    "last_loss=None\n",
    "epochs=1000\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w=np.zeros(weights.shape)\n",
    "    for x,y in zip(train_features.values,train_labels):\n",
    "        #print(x.shape, weights.shape)\n",
    "    \n",
    "        output=sigmoid(np.matmul(x,weights))\n",
    "\n",
    "        error=y-output\n",
    "\n",
    "        error_term = error*output*(1-output)\n",
    "\n",
    "        del_w+=error_term*x\n",
    "        weights+=learnrate*del_w/n_rows\n",
    "\n",
    "    if e % (epochs / 10) == 0:\n",
    "        out = sigmoid(np.dot(train_features, weights))\n",
    "        loss = np.mean((out-y) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "            \n",
    "# Calculate accuracy on test data\n",
    "tes_out = sigmoid(np.dot(test_features, weights))\n",
    "predictions = tes_out > 0.5\n",
    "#print(predictions)\n",
    "accuracy = np.mean(predictions == test_labels)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  0.1740787289817364\n",
      "Train Loss:  0.1740602723290662\n",
      "Train Loss:  0.17404181769935584\n",
      "Train Loss:  0.17402336509243663\n",
      "Train Loss:  0.17400491450813985\n",
      "Train Loss:  0.17398646594629688\n",
      "Train Loss:  0.17396801940673892\n",
      "Train Loss:  0.1739495748892974\n",
      "Train Loss:  0.1739311323938038\n",
      "Train Loss:  0.17391269192008932\n",
      "Prediction accuracy: 0.775\n"
     ]
    }
   ],
   "source": [
    "#paramters\n",
    "learnrate=0.005\n",
    "n_hidden=2\n",
    "epochs=1000\n",
    "\n",
    "#np.random.seed(21)\n",
    "\n",
    "\n",
    "weights_input_hidden=np.random.normal(scale=1/np.sqrt(n_features),size=(n_features,n_hidden))\n",
    "weights_hidden_output=np.random.normal(scale=1/np.sqrt(n_features),size=n_hidden)\n",
    "\n",
    "last_loss=None\n",
    "\n",
    "for e in range(epochs):\n",
    "    for x,y in zip(train_features.values,train_labels.values):\n",
    "        \n",
    "        del_w_input_hidden=np.zeros(shape=weights_input_hidden.shape)\n",
    "        del_w_hidden_output=np.zeros(shape=weights_hidden_output.shape)\n",
    "        \n",
    "        #forward pass\n",
    "        hidden_layer_input=np.dot(x,weights_input_hidden)\n",
    "        hidden_layer_output=sigmoid(hidden_layer_input)\n",
    "        \n",
    "        output_layer_in=np.dot(hidden_layer_output,weights_hidden_output)\n",
    "        output=sigmoid(output_layer_in)\n",
    "        \n",
    "        #backward pass\n",
    "        \n",
    "        error=y-output\n",
    "        error_term=error*output*(1-output)\n",
    "        hidden_error_term=weights_hidden_output*error_term*hidden_layer_output*(1-hidden_layer_output)\n",
    "        \n",
    "        del_w_hidden_output+=error_term*hidden_layer_output\n",
    "        del_w_input_hidden+=hidden_error_term*x[:,None]\n",
    "        \n",
    "    #weights update\n",
    "    \n",
    "    weights_hidden_output+=learnrate*del_w_hidden_output/n_rows\n",
    "    weights_input_hidden+=learnrate*del_w_input_hidden/n_rows\n",
    "    \n",
    "    if e%(epochs/10)==0:\n",
    "        hidden_out=sigmoid(np.dot(x,weights_input_hidden))\n",
    "        out=sigmoid(np.dot(hidden_out,weights_hidden_output))\n",
    "        \n",
    "        loss=np.mean((y-out)**2)\n",
    "        if last_loss and last_loss<loss:\n",
    "            print(\"Train Loss: \", loss, \"Warning-Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train Loss: \", loss)\n",
    "        \n",
    "        last_loss=loss\n",
    "        \n",
    "#Accuracy\n",
    "hidden=sigmoid(np.dot(test_features,weights_input_hidden))\n",
    "test_out=sigmoid(np.dot(hidden,weights_hidden_output))\n",
    "predictions=test_out>0.5\n",
    "accuracy=np.mean(predictions==test_labels)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
